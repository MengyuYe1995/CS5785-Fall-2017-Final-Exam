{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from global_constants import *\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "import csv\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "# constants\n",
    "minimum_number_of_labels = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_normalised_prob(prediction_weights):\n",
    "    normalizing_factor = sum(prediction_weights)\n",
    "    return np.array(prediction_weights)/normalizing_factor\n",
    "\n",
    "def normalize_rows(ini_matrix, minimum_number_of_labels, binary_predictions=None):\n",
    "    matrix = ini_matrix.copy()\n",
    "    matrix_argsort = matrix.argsort()\n",
    "    \n",
    "    # Iterate over i\n",
    "    for i in range(len(matrix)):\n",
    "\n",
    "        # Decide number to roll with\n",
    "        number_to_use = minimum_number_of_labels\n",
    "        \n",
    "        # Zero out other values\n",
    "        for k in range(len(matrix[i])):\n",
    "            matrix[i][k] = 0 if k not in matrix_argsort[i][-number_to_use:] else matrix[i][k]\n",
    "\n",
    "        # normalize\n",
    "        matrix[i] = get_normalised_prob(matrix[i])\n",
    "\n",
    "        # Sanity Check\n",
    "        # print(sum(matrix[i]))\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "def get_ordered_data_frame(csv_path, mode='train', number_of_train_features=1000, tag=\"fc\"):\n",
    "    data_frame = pd.read_csv(join(data_path, csv_path), names=[\"name\"] + [tag + str(k) for k in range(number_of_train_features)])\n",
    "    data_frame[\"file_name_index\"] = pd.to_numeric(data_frame.name.str.extract(\"((?<=[images_\" + mode + \"\\/])\\d*(?=\\.))\", expand=False))\n",
    "    data_frame.sort_values('file_name_index', inplace=True)\n",
    "    return data_frame.drop([\"name\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 7771)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ground Truth\n",
    "\n",
    "better_tag_data = pd.read_csv('better_train_10_tags_adj&noun&verb.csv')\n",
    "\n",
    "better_tag_test_data = pd.read_csv('better_test_10_tags_adj&noun&verb.csv')\n",
    "\n",
    "better_tag_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "\n",
    "train_tags = pd.read_csv(\"processed_tags.csv\")\n",
    "pca_train_tags = pca.fit_transform(train_tags.drop([\"Name\"], axis=1))\n",
    "\n",
    "train_fc_data = get_ordered_data_frame('features_train/features_resnet1000_train.csv', number_of_train_features=1000, tag=\"fc\")\n",
    "train_intermediate_data = get_ordered_data_frame('features_train/features_resnet1000intermediate_train.csv', number_of_train_features=2048, tag=\"pl\")\n",
    "\n",
    "combined_train_net_data = train_intermediate_data.join(train_fc_data.set_index('file_name_index'), on='file_name_index')\n",
    "# tags_fc_pool_train_net_data = combined_train_net_data.join(train_tags.drop([\"Name\"], axis=1), on=\"file_name_index\")\n",
    "pca_fc_pool_train_net_data = combined_train_net_data.join(pd.DataFrame(pca_train_tags), on=\"file_name_index\")\n",
    "\n",
    "# Test\n",
    "\n",
    "test_tags = pd.read_csv(\"processed_tags_test.csv\")\n",
    "pca_test_tags = pca.transform(test_tags.drop([\"Name\"], axis=1))\n",
    "\n",
    "test_fc_data = get_ordered_data_frame('features_test/features_resnet1000_test.csv', \"test\", number_of_train_features=1000, tag=\"fc\")     \n",
    "test_intermediate_data = get_ordered_data_frame('features_test/features_resnet1000intermediate_test.csv', \"test\", number_of_train_features=2048, tag=\"pl\")     \n",
    "\n",
    "combined_test_net_data = test_intermediate_data.join(test_fc_data.set_index('file_name_index'), on='file_name_index')\n",
    "# tags_fc_pool_test_net_data = combined_test_net_data.join(test_tags.drop([\"Name\"], axis=1), on=\"file_name_index\")\n",
    "pca_fc_pool_test_net_data = combined_test_net_data.join(pd.DataFrame(pca_test_tags), on=\"file_name_index\")\n",
    "\n",
    "# X = train_fc_data.drop([\"file_name_index\"], axis=1).values\n",
    "# X_Test = test_fc_data.drop([\"file_name_index\"], axis=1).values\n",
    "\n",
    "# X = combined_train_net_data.drop([\"file_name_index\"], axis=1).values\n",
    "# X_Test = combined_test_net_data.drop([\"file_name_index\"], axis=1).values\n",
    "\n",
    "X_Test = pca_fc_pool_test_net_data.drop([\"file_name_index\"], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "n_components = 2000\n",
    "\n",
    "if train_size != 1.0:\n",
    "    X_Train, X_Val, Y_train, Y_Val = train_test_split(pca_fc_pool_train_net_data, better_tag_data.values, train_size=0.8)\n",
    "\n",
    "    gt_files = X_Val.file_name_index.values\n",
    "    better_tag_val_data = Y_Val.copy()\n",
    "\n",
    "    X_Train = X_Train.drop([\"file_name_index\"], axis=1).values    \n",
    "    \n",
    "    X_Val = X_Val.drop([\"file_name_index\"], axis=1).values\n",
    "    \n",
    "    overall_pca = PCA(n_components=n_components)\n",
    "    X_Train = overall_pca.fit_transform(X_Train)\n",
    "    X_Val = overall_pca.transform(X_Val)\n",
    "    X_Test = overall_pca.transform(X_Test)\n",
    "\n",
    "    Y_train[Y_train != 0] = 1    \n",
    "#     Y_Val[Y_Val != 0] = 1\n",
    "\n",
    "else:\n",
    "    X_Train, Y_train = pca_fc_pool_train_net_data.drop([\"file_name_index\"], axis=1).values, better_tag_data.values\n",
    "    Y_train[Y_train != 0] = 1\n",
    "    \n",
    "    overall_pca = PCA(n_components=n_components)\n",
    "    X_Train = overall_pca.fit_transform(X_Train)\n",
    "    X_Test = overall_pca.transform(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy_on_set(X_Val, better_tag_val_data, gt_files, classifier):\n",
    "\n",
    "    Y_val_proba = classifier.predict_proba(X_Val)\n",
    "    temp_simi = cdist(better_tag_val_data, Y_val_proba, metric='cosine')\n",
    "\n",
    "    score = 0.0\n",
    "    for i_check in range(len(X_Val)):\n",
    "        pred_list = list(temp_simi[i_check].argsort()[:20])\n",
    "\n",
    "        k = [gt_files[i] for i in pred_list]\n",
    "        if gt_files[i_check] in k:\n",
    "            score += float(20 - k.index(gt_files[i_check]))/20\n",
    "\n",
    "    return temp_simi, score/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_classifier = MLPClassifier(hidden_layer_sizes=(700), verbose=True, max_iter=3, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2000) (8000, 7771) (2000, 2000) (2000, 7771) (2000, 2000) (2000, 7771)\n",
      "Iteration 1, loss = 515.41834554\n",
      "Iteration 2, loss = 81.04675279\n",
      "Iteration 3, loss = 72.73065632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on val : 0.42369999999999997\n",
      "Iteration 4, loss = 71.15827050\n",
      "Iteration 5, loss = 58.52234475\n",
      "Iteration 6, loss = 52.04865810\n",
      "Accuracy on val : 0.603225000000003\n",
      "Iteration 7, loss = 51.93734045\n",
      "Iteration 8, loss = 44.78489297\n"
     ]
    }
   ],
   "source": [
    "print(X_Train.shape, Y_train.shape, X_Val.shape, better_tag_val_data.shape, X_Test.shape, better_tag_test_data.shape)\n",
    "for i in range(9):\n",
    "    first_classifier.fit(X_Train, Y_train)\n",
    "    pickle.dump(first_classifier, open(\"3000_classifier_\" + str(i) + \".pkl\", \"wb\"))\n",
    "    \n",
    "    _, accuracy = get_accuracy_on_set(X_Val, better_tag_val_data, gt_files, first_classifier)\n",
    "    print(\"Accuracy on val : \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_Train_copy = X_Train.copy()\n",
    "# X_Val_copy = X_Val.copy()\n",
    "# X_Test_copy = X_Test.copy()\n",
    "\n",
    "next_training_input = np.hstack((X_Train, first_classifier.predict_proba(X_Train)))\n",
    "next_val_input = np.hstack((X_Val, first_classifier.predict_proba(X_Val)))\n",
    "next_test_input = np.hstack((X_Test, first_classifier.predict_proba(X_Test)))\n",
    "\n",
    "next_training_input.shape, next_val_input.shape, next_test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second_classifier = MLPClassifier(hidden_layer_sizes=(2000), verbose=True, max_iter=3, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 9771) (8000, 7771) (2000, 9771) (2000, 7771) (2000, 9771) (2000, 7771)\n",
      "Iteration 1, loss = 702.20040679\n",
      "Iteration 2, loss = 90.88421398\n",
      "Iteration 3, loss = 76.43485135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on val : 0.4518500000000003\n",
      "Iteration 4, loss = 70.54190289\n",
      "Iteration 5, loss = 57.12677862\n",
      "Iteration 6, loss = 50.05369079\n",
      "Accuracy on val : 0.6511500000000013\n",
      "Iteration 7, loss = 48.69385183\n",
      "Iteration 8, loss = 40.85943049\n",
      "Iteration 9, loss = 34.75315035\n",
      "Accuracy on val : 0.6672750000000027\n",
      "Iteration 10, loss = 33.17021366\n",
      "Iteration 11, loss = 26.22911522\n",
      "Iteration 12, loss = 20.89738006\n",
      "Accuracy on val : 0.6511500000000034\n",
      "Iteration 13, loss = 19.31910056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:565: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-93cb9392acd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"500_second_classifier_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy_on_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_val_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetter_tag_val_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy on val : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-61a620b5a675>\u001b[0m in \u001b[0;36mget_accuracy_on_set\u001b[0;34m(X_Val, better_tag_val_data, gt_files, classifier)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_accuracy_on_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetter_tag_val_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mY_val_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtemp_simi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetter_tag_val_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \"\"\"\n\u001b[1;32m   1015\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coefs_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \"\"\"\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;31m# Make sure self.hidden_layer_sizes is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# everything is finite; fall back to O(n) space np.isfinite to prevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# false positives from overflow in sum method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n\u001b[0m\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(next_training_input.shape, Y_train.shape, next_val_input.shape, better_tag_val_data.shape, next_test_input.shape, better_tag_test_data.shape)\n",
    "for i in range(9):\n",
    "    second_classifier.fit(next_training_input, Y_train)\n",
    "    pickle.dump(second_classifier, open(\"500_second_classifier_\" + str(i) + \".pkl\", \"wb\"))\n",
    "    \n",
    "    _, accuracy = get_accuracy_on_set(next_val_input, better_tag_val_data, gt_files, second_classifier)\n",
    "    print(\"Accuracy on val : \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(X_Test.shape)\n",
    "Y_test_proba = first_classifier.predict_proba(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simi = cdist(better_tag_test_data, Y_test_proba, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k = pd.DataFrame(cdist(better_tag_test_data, Y_test_proba, metric='cosine')).to_csv(\"simi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows=[['Descritpion_ID', 'Top_20_Image_IDs']]\n",
    "for i in range(len(better_tag_test_data)):\n",
    "    buffer1=[]\n",
    "    buffer1=simi[i].argsort()[:20]\n",
    "    rows.append([str(i) + \".txt\", \" \".join([str(value) + \".jpg\" for value in buffer1])])\n",
    "csv.writer(open(\"submission_try.csv\", \"w\")).writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_check=1\n",
    "\n",
    "output_statement = rows[d_check + 1][1]\n",
    "\n",
    "row, col = 5,5\n",
    "\n",
    "f, ax = plt.subplots(nrows=row, ncols=col, figsize=(30,30))\n",
    "for index, image_1 in enumerate(output_statement.split()):\n",
    "    if index == row*col:\n",
    "        break\n",
    "    img=mpimg.imread('data/images_test/' + image_1)\n",
    "    \n",
    "\n",
    "    ax[int(index/row), index%col].imshow(img)\n",
    "    ax[int(index/row), index%col].set_title(image_1, fontsize=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
